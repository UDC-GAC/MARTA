Dirty notes:
------------

* Stores are quite hard to measure. Within the measurement loop (TSTEPS), for
simple load/stores there were stalls. In order to avoid this, I have made this 
simple trick: store in the same array but different location. This is no 100% 
precise but it should do the trick (ONLY FOR MEASURING THE IMPACT OF STORE
INSTRUCTIONS, E.G. WHEN REDUCING TO AN ELEMENT)

* Everything is holistic, for sure, however, the "simple" approach of:
    cost_vpack(A) + cost_vpack(x) + cost_vpack(y) + cost_operations() +
    cost_store(y)
    
reports good results for 4 FMADD operations with 4 operands.

* For packing:
    * Vector length: 128 vs 256
    * Cache lines used: seems to have effect, but gather seems to hide this
    * How contiguous data is: it is not the same 2 loads + insert than a gather
    * Masks have detrimental performance: seems better to use gather than, for
    instance a maskload + insert. I was trying maskloads to "take advantage" of
    contiguous data, e.g. 0,1,2,6, could be maskload(x[0],(0,-1,-1,-1)) +
    insert(x[6], ...)
    * Adding costs of individual loads is not always 100% accurate: they may be
    overlapped and, then, total execution time may be lower:
        vop0 = load()
        vop1 = load()

        these could be overlapped

* Reductions:
    * log(N) steps (reducing to same element, e.g. y[0] += A[0..7] * x[0..7])
    * Avoids loading y onto the accumulator vector

